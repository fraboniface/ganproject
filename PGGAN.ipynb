{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive growing of GANs prototype\n",
    "\n",
    "- smooth transitions\n",
    "- minibatch STD\n",
    "- pixel-wise feature vector normalisation (not in the networks)\n",
    "- spectral normalisation\n",
    "- He initialisation\n",
    "- chrome tire rim\n",
    "- 7.1 Dolby Surround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules import conv\n",
    "from torch.nn.modules.utils import _pair\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable, grad\n",
    "import torch.nn.functional as F\n",
    "from torchvision  import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchSDLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MinibatchSDLayer, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_batch_std = x.std(0).mean()\n",
    "        mean_batch_std = mean_batch_std.expand(x.size(0), 1, x.size(-1), x.size(-1))\n",
    "        return torch.cat([x, mean_batch_std], 1)\n",
    "    \n",
    "    \n",
    "class PixelWiseFeatureNormLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelWiseFeatureNormLayer, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x / x.norm(2,1)\n",
    "    \n",
    "    \n",
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "def max_singular_value(W, u=None, Ip=1):\n",
    "    \"\"\"\n",
    "    power iteration for weight parameter\n",
    "    \"\"\"\n",
    "    if u is None:\n",
    "        u = torch.FloatTensor(1, W.size(0)).normal_()\n",
    "        \n",
    "    _u = u\n",
    "    for _ in range(Ip):\n",
    "        _v = l2normalize(torch.matmul(_u, W), eps=1e-12)\n",
    "        _u = l2normalize(torch.matmul(_v, torch.transpose(W, 0, 1)), eps=1e-12)\n",
    "        \n",
    "    sigma = torch.sum(F.linear(_u, torch.transpose(W, 0, 1)) * _v)\n",
    "    return sigma, _u\n",
    "    \n",
    "    \n",
    "class SNConv2d(conv._ConvNd):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        padding = _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        super(SNConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, False, _pair(0), groups, bias)\n",
    "        self.u = nn.Parameter(torch.Tensor(1, out_channels).normal_(), requires_grad=False)\n",
    "        #self.u = torch.Tensor(1, out_channels).normal_()\n",
    "\n",
    "    @property\n",
    "    def W_(self):\n",
    "        w_mat = self.weight.view(self.weight.size(0), -1).data\n",
    "        sigma, _u = max_singular_value(w_mat, self.u.data)\n",
    "        self.u.data = _u\n",
    "        return self.weight / sigma\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.conv2d(input, self.W_, self.bias, self.stride, self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrowingGenerator(nn.Module):\n",
    "    def __init__(self, zdim=100, init_size=4, final_size=128, n_feature_maps=128):\n",
    "        super(GrowingGenerator, self).__init__()\n",
    "       \n",
    "        self.init_size = init_size\n",
    "        self.final_size = final_size\n",
    "        init_nfm = 8*n_feature_maps\n",
    "        \n",
    "        self.layers = [\n",
    "            #1x1\n",
    "            nn.ConvTranspose2d(zdim, init_nfm, 4, 1, 0, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            #4x4\n",
    "            nn.Conv2d(init_nfm, init_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "            #4x4\n",
    "        ]\n",
    "        self.main = nn.Sequential(*self.layers)\n",
    "        self.old = self.main\n",
    "        \n",
    "        self.to_rgb = nn.Conv2d(init_nfm, 3, 1, 1, 0, bias=False)\n",
    "        self.old_rgb = self.to_rgb\n",
    "        self.current_size = init_size\n",
    "        self.current_nfm = init_nfm\n",
    "        \n",
    "        self.transitioning = False\n",
    "        \n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return self._alpha\n",
    "        \n",
    "    @alpha.setter\n",
    "    def alpha(self, v):\n",
    "        if v > 1:\n",
    "            self.transitioning = False\n",
    "        self._alpha = v\n",
    "                \n",
    "    def forward(self, x):\n",
    "        if self.transitioning:\n",
    "            new = self.main(x)\n",
    "            new = self.to_rgb(new)\n",
    "            old = F.upsample(self.old(x), scale_factor=2)\n",
    "            old = self.old_rgb(old)\n",
    "            x = self.alpha*new + (1-self.alpha)*old\n",
    "        \n",
    "        else:   \n",
    "            x = self.main(x)\n",
    "            x = self.to_rgb(x)\n",
    "            \n",
    "        return F.tanh(x)\n",
    "    \n",
    "    def grow(self):\n",
    "        if self.current_size == self.final_size:\n",
    "            print(\"Network can't grow more\")\n",
    "            return\n",
    "        \n",
    "        self.transitioning = True\n",
    "        self._alpha = 0\n",
    "        \n",
    "        if self.current_size in [8,32]: # don't decrease everytime because otherwise it's too fast\n",
    "            future_nfm = self.current_nfm\n",
    "        else:\n",
    "            future_nfm = int(self.current_nfm / 2)\n",
    "            \n",
    "        self.old = self.main\n",
    "        self.old_rgb = self.to_rgb\n",
    "            \n",
    "        block = [\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(self.current_nfm, future_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(future_nfm, future_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        self.layers += block\n",
    "        self.main = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.current_size *= 2\n",
    "        self.current_nfm = future_nfm\n",
    "        self.to_rgb = nn.Conv2d(self.current_nfm, 3, 1, 1, 0, bias=False)\n",
    "        \n",
    "        self.new_parameters = nn.Sequential(*block).parameters()\n",
    "        \n",
    "        \n",
    "class GrowingDiscriminator(nn.Module):\n",
    "    def __init__(self, init_size=4, final_size=128, n_feature_maps=128):\n",
    "        super(GrowingDiscriminator, self).__init__()\n",
    "        self.init_size = init_size\n",
    "        self.final_size = final_size\n",
    "        init_nfm = 8 * n_feature_maps\n",
    "        \n",
    "        self.from_rgb = nn.Sequential(\n",
    "            SNConv2d(3, init_nfm, 1, 1, 0, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layers = [\n",
    "            MinibatchSDLayer(),\n",
    "            #4x4\n",
    "            SNConv2d(init_nfm+1, init_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            #4x4\n",
    "            #nn.Conv2d(init_nfm, init_nfm, 4, 1, 0, bias=False),\n",
    "            SNConv2d(init_nfm, 1, 4, 1, 0, bias=False),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #1x1\n",
    "            #nn.Conv2d(init_nfm, 1, 1, 1, 0, bias=False) # equivalent to fully connected\n",
    "            #nn.Sigmoid()\n",
    "        ]\n",
    "        self.main = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.current_size = init_size\n",
    "        self.current_nfm = init_nfm\n",
    "        \n",
    "        self.transitioning = False\n",
    "        \n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return self._alpha\n",
    "        \n",
    "    @alpha.setter\n",
    "    def alpha(self, v):\n",
    "        if v > 1:\n",
    "            self.transitioning = False\n",
    "        self._alpha = v\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.size(3) != self.current_size:\n",
    "            print(\"input is of the wrong size (should be {})\".format(self.current_size))\n",
    "            return\n",
    "        \n",
    "        if self.transitioning:\n",
    "            new = self.from_rgb(x)\n",
    "            new = self.new(new)\n",
    "            old = F.avg_pool2d(x, 2)\n",
    "            old = self.old_rgb(old)\n",
    "            x = self.alpha*new + (1-self.alpha)*old\n",
    "            output = self.old(x)\n",
    "            \n",
    "        else:\n",
    "            x = self.from_rgb(x)\n",
    "            output = self.main(x)\n",
    "            \n",
    "        return output.view(-1,1).squeeze()\n",
    "    \n",
    "    def grow(self):\n",
    "        if self.current_size == self.final_size:\n",
    "            print(\"Network can't grow more\")\n",
    "            return\n",
    "        \n",
    "        self.transitioning = True\n",
    "        self.alpha = 0\n",
    "        \n",
    "        if self.current_size in [8,32]:\n",
    "            future_nfm = self.current_nfm\n",
    "        else:\n",
    "            future_nfm = int(self.current_nfm / 2)\n",
    "            \n",
    "        self.old = self.main\n",
    "        self.old_rgb = self.from_rgb\n",
    "        \n",
    "        block = [\n",
    "            SNConv2d(future_nfm, future_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            SNConv2d(future_nfm, self.current_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(2)\n",
    "        ]\n",
    "        self.new = nn.Sequential(*block)\n",
    "        self.layers = block + self.layers\n",
    "        self.main = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.current_size *= 2\n",
    "        self.current_nfm = future_nfm\n",
    "        self.from_rgb = SNConv2d(3, self.current_nfm, 1, 1, 0, bias=False)\n",
    "        \n",
    "        self.new_parameters = nn.Sequential(*block).parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "\t[\n",
    "\t    transforms.ToTensor(),\n",
    "\t    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "\t])\n",
    "dataset = datasets.ImageFolder('paintings64/', transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrowingDiscriminator(\n",
       "  (from_rgb): Sequential(\n",
       "    (0): SNConv2d (3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(0.2, inplace)\n",
       "  )\n",
       "  (main): Sequential(\n",
       "    (0): MinibatchSDLayer(\n",
       "    )\n",
       "    (1): SNConv2d (1025, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): LeakyReLU(0.2, inplace)\n",
       "    (3): SNConv2d (1024, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zdim = 100\n",
    "n_feature_maps = 128\n",
    "init_size = 4\n",
    "final_size = 64\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_uniform(m.weight.data)\n",
    "        \n",
    "G = GrowingGenerator(zdim, init_size, final_size, n_feature_maps)\n",
    "G.apply(weights_init)\n",
    "D = GrowingDiscriminator(init_size, final_size, n_feature_maps)\n",
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "beta1 = 0\n",
    "beta2 = 0.99\n",
    "G_optimiser = optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "D_optimiser = optim.Adam(filter(lambda p: p.requires_grad, D.parameters()), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_penalty(real, fake, D, gamma=1, gpu=True):\n",
    "    batch_size = real.size(0)\n",
    "    alpha = torch.rand(batch_size,1,1,1)\n",
    "    alpha = Variable(alpha.expand_as(real))\n",
    "    if gpu:\n",
    "        alpha = alpha.cuda()\n",
    "\n",
    "    interpolation = alpha * real + (1-alpha) * fake # everything is a Variable so interpolation should be one too\n",
    "    D_itp = D(interpolation)\n",
    "    if gpu:\n",
    "        gradients = grad(outputs=D_itp, inputs=interpolation, grad_outputs=torch.ones(D_itp.size()).cuda(), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    else:\n",
    "        gradients = grad(outputs=D_itp, inputs=interpolation, grad_outputs=torch.ones(D_itp.size()), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    GP = ((gradients.norm(2, dim=1) - gamma)**2 / gamma**2).mean()\n",
    "    return GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "64\n",
      "128\n",
      "192\n",
      "0\n",
      "0.001 0.001\n",
      "64\n",
      "0.002 0.002\n",
      "128\n",
      "0.003 0.003\n",
      "192\n",
      "0.004 0.004\n",
      "0\n",
      "0.001 0.001\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/francois/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a2a9febfa31e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-97ef40fa4d0c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitioning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "lambda_ = 10\n",
    "gamma = 750\n",
    "epsilon_drift = 1e-3\n",
    "examples_seen = 0\n",
    "current_size = 4\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in dataloader:\n",
    "        print(examples_seen)\n",
    "        x = Variable(img)\n",
    "        if x.size(-1) > current_size:\n",
    "            ratio = int(x.size(0)/current_size)\n",
    "            x = F.avg_pool2d(x, ratio)\n",
    "        \n",
    "        # D training, n_critic=1\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "        D.zero_grad\n",
    "        D_real = D(x)\n",
    "        \n",
    "        z = torch.FloatTensor(batch_size, zdim, 1, 1).normal_()\n",
    "        z = Variable(z)\n",
    "        fake = G(z)\n",
    "        D_fake = D(fake.detach())\n",
    "                \n",
    "        D_err = torch.mean(D_real) - torch.mean(D_fake)\n",
    "        D_optimiser.step()\n",
    "        \n",
    "        # G training\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False # saves computation\n",
    "            \n",
    "        z = torch.FloatTensor(batch_size, zdim, 1, 1).normal_()\n",
    "        z = Variable(z)\n",
    "        fake = G(z)\n",
    "        G_err = torch.mean(D(fake))\n",
    "        G_optimiser.step()\n",
    "        \n",
    "        examples_seen += img.size(0)\n",
    "        \n",
    "        if G.transitioning:\n",
    "            G.alpha += 1e-3\n",
    "            D.alpha += 1e-3\n",
    "            print(G.alpha, D.alpha)\n",
    "        \n",
    "        \n",
    "    # we grow every 100K images. 600Kin the paper, plus transitions, we'll see\n",
    "        if examples_seen > 200:\n",
    "            examples_seen = 0\n",
    "            current_size *= 2\n",
    "            G.grow()\n",
    "            G_optimiser.add_param_group({'params': G.new_parameters})\n",
    "            D.grow()\n",
    "            D_optimiser.add_param_group({'params': filter(lambda p: p.requires_grad, D.new_parameters)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7813"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.linspace(0,1,int(5e5/64)+1)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30000/64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
