{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive growing of GANs prototype\n",
    "\n",
    "To add:\n",
    "- smooth transitions -> hard\n",
    "- pixel-wise feature normalisation in generator -> easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules import conv\n",
    "from torch.nn.modules.utils import _pair\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable, grad\n",
    "import torch.nn.functional as F\n",
    "from torchvision  import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO IMPLEMENT\n",
    "# you can add these to a Sequential\n",
    "\n",
    "class MinibatchSDLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MinibatchSDLayer, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_batch_std = x.std(0).mean()\n",
    "        mean_batch_std = mean_batch_std.expand(x.size(0), 1, x.size(-1), x.size(-1))\n",
    "        return torch.cat([x, mean_batch_std], 1)\n",
    "    \n",
    "    \n",
    "class PixelWiseFeatureNormLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelWiseFeatureNormLayer, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrowingGenerator(nn.Module):\n",
    "    def __init__(self, zdim=100, init_size=4, final_size=128, n_feature_maps=128):\n",
    "        super(GrowingGenerator, self).__init__()\n",
    "       \n",
    "        self.init_size = init_size\n",
    "        self.final_size = final_size\n",
    "        init_nfm = 8*n_feature_maps\n",
    "        \n",
    "        self.layers = [\n",
    "            #1x1\n",
    "            nn.ConvTranspose2d(zdim, init_nfm, 4, 1, 0, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            #4x4\n",
    "            nn.Conv2d(init_nfm, init_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "            #4x4\n",
    "        ]\n",
    "        self.main = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.to_rgb = nn.Conv2d(init_nfm, 3, 1, 1, 0, bias=False)\n",
    "        self.current_size = init_size\n",
    "        self.current_nfm = init_nfm\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        x = self.to_rgb(x)\n",
    "        return F.tanh(x)\n",
    "\n",
    "    def grow(self):\n",
    "        if self.current_size == self.final_size:\n",
    "            print(\"Network can't grow more\")\n",
    "            return\n",
    "        \n",
    "        if self.current_size in [8,32]: # don't decrease everytime because otherwise it's too fast\n",
    "            future_nfm = self.current_nfm\n",
    "        else:\n",
    "            future_nfm = int(self.current_nfm / 2)\n",
    "            \n",
    "        block = [\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(self.current_nfm, future_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(future_nfm, future_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        self.layers += block\n",
    "        self.main = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.current_size *= 2\n",
    "        self.current_nfm = future_nfm\n",
    "        self.to_rgb = nn.Conv2d(self.current_nfm, 3, 1, 1, 0, bias=False)\n",
    "        \n",
    "        self.new_parameters = nn.Sequential(*block).parameters()\n",
    "        \n",
    "        \n",
    "class GrowingDiscriminator(nn.Module):\n",
    "    def __init__(self, init_size=4, final_size=128, n_feature_maps=128):\n",
    "        super(GrowingDiscriminator, self).__init__()\n",
    "        self.init_size = init_size\n",
    "        self.final_size = final_size\n",
    "        init_nfm = 8 * n_feature_maps\n",
    "        \n",
    "        self.from_rgb = nn.Sequential(\n",
    "            SNConv2d(3, init_nfm, 1, 1, 0, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layers = [\n",
    "            MinibatchSDLayer(),\n",
    "            #4x4\n",
    "            SNConv2d(init_nfm+1, init_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            #4x4\n",
    "            #nn.Conv2d(init_nfm, init_nfm, 4, 1, 0, bias=False),\n",
    "            SNConv2d(init_nfm, 1, 4, 1, 0, bias=False),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "            #1x1\n",
    "            #nn.Conv2d(init_nfm, 1, 1, 1, 0, bias=False) # equivalent to fully connected\n",
    "            #nn.Sigmoid()\n",
    "        ]\n",
    "        self.main = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.current_size = init_size\n",
    "        self.current_nfm = init_nfm\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.size(3) != self.current_size:\n",
    "            print(\"input is of the wrong size (should be {})\".format(self.current_size))\n",
    "            return\n",
    "        \n",
    "        x = self.from_rgb(x)\n",
    "        output = self.main(x)\n",
    "        return output.view(-1,1).squeeze()\n",
    "    \n",
    "    def grow(self):\n",
    "        if self.current_size == self.final_size:\n",
    "            print(\"Network can't grow more\")\n",
    "            return  \n",
    "        \n",
    "        if self.current_size in [8,32]:\n",
    "            future_nfm = self.current_nfm\n",
    "        else:\n",
    "            future_nfm = int(self.current_nfm / 2)\n",
    "        \n",
    "        block = [\n",
    "            SNConv2d(future_nfm, future_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            SNConv2d(future_nfm, self.current_nfm, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(2)\n",
    "        ]\n",
    "        self.layers = block + self.layers\n",
    "        self.main = nn.Sequential(*self.layers)\n",
    "        \n",
    "        self.current_size *= 2\n",
    "        self.current_nfm = future_nfm\n",
    "        self.from_rgb = SNConv2d(3, self.current_nfm, 1, 1, 0, bias=False)\n",
    "        \n",
    "        self.new_parameters = nn.Sequential(*block).parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "\t[\n",
    "\t    transforms.ToTensor(),\n",
    "\t    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "\t])\n",
    "dataset = datasets.ImageFolder('paintings64/', transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrowingDiscriminator(\n",
       "  (from_rgb): Sequential(\n",
       "    (0): SNConv2d (3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(0.2, inplace)\n",
       "  )\n",
       "  (main): Sequential(\n",
       "    (0): MinibatchSDLayer(\n",
       "    )\n",
       "    (1): SNConv2d (1025, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): LeakyReLU(0.2, inplace)\n",
       "    (3): SNConv2d (1024, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zdim = 100\n",
    "n_feature_maps = 128\n",
    "init_size = 4\n",
    "final_size = 64\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_uniform(m.weight.data)\n",
    "        \n",
    "G = GrowingGenerator(zdim, init_size, final_size, n_feature_maps)\n",
    "G.apply(weights_init)\n",
    "D = GrowingDiscriminator(init_size, final_size, n_feature_maps)\n",
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "beta1 = 0\n",
    "beta2 = 0.99\n",
    "G_optimiser = optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "D_optimiser = optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_penalty(real, fake, D, gamma=1, gpu=True):\n",
    "    batch_size = real.size(0)\n",
    "    alpha = torch.rand(batch_size,1,1,1)\n",
    "    alpha = Variable(alpha.expand_as(real))\n",
    "    if gpu:\n",
    "        alpha = alpha.cuda()\n",
    "\n",
    "    interpolation = alpha * real + (1-alpha) * fake # everything is a Variable so interpolation should be one too\n",
    "    D_itp = D(interpolation)\n",
    "    if gpu:\n",
    "        gradients = grad(outputs=D_itp, inputs=interpolation, grad_outputs=torch.ones(D_itp.size()).cuda(), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    else:\n",
    "        gradients = grad(outputs=D_itp, inputs=interpolation, grad_outputs=torch.ones(D_itp.size()), create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    GP = ((gradients.norm(2, dim=1) - gamma)**2 / gamma**2).mean()\n",
    "    return GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d97b7af12098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# D training, n_critic=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "lambda_ = 10\n",
    "gamma = 750\n",
    "epsilon_drift = 1e-3\n",
    "examples_seen = 0\n",
    "current_size = 4\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in dataloader:\n",
    "        x = Variable(img)\n",
    "        if x.size(-1) > current_size:\n",
    "            ratio = int(x.size(0)/current_size)\n",
    "            x = F.avg_pool2d(x, ratio)\n",
    "        \n",
    "        # D training, n_critic=1\n",
    "        for p in D.parameters:\n",
    "            p.requires_grad = True\n",
    "            \n",
    "        D.zero_grad\n",
    "        D_real = D(x)\n",
    "        \n",
    "        z = torch.FloatTensor(batch_size, zdim, 1, 1).normal_()\n",
    "        z = Variable(z)\n",
    "        fake = G(z)\n",
    "        D_fake = D(fake.detach())\n",
    "                \n",
    "        D_err = torch.mean(D_real) - torch.mean(D_fake)\n",
    "        D_optimiser.step()\n",
    "        \n",
    "        # G training\n",
    "        for p in D.parameters:\n",
    "            p.requires_grad = False # saves computation\n",
    "            \n",
    "        z = torch.FloatTensor(batch_size, zdim, 1, 1).normal_()\n",
    "        z = Variable(z)\n",
    "        fake = G(z)\n",
    "        G_err = torch.mean(D(fake))\n",
    "        G_optimiser.step()\n",
    "        \n",
    "        examples_seen += img.size(0)\n",
    "    \n",
    "    # we grow every 100K images. 600Kin the paper, plus transitions, we'll see\n",
    "    if examples_seen % 1e5 == 0:\n",
    "        examples_seen = 0\n",
    "        current_size *= 2\n",
    "        G.grow()\n",
    "        G_optimiser.add_param_group({'params': G.new_parameters})\n",
    "        D.grow()\n",
    "        D_optimiser.add_param_group({'params': D.new_parameters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = GrowingGenerator(zdim=100, init_size=4, final_size=64, n_feature_maps=128)\n",
    "G.load_state_dict(torch.load('results/saved_data/paintings64_PG_GAN_generator', map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.current_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
